2025-03-31 04:25:46,636 - root - INFO - {'seed': 2023, 'model_dir': '../model', 'checkpoint_dir': '../checkpoint', 'model_name': 'Movietweetings_sequential.pt', 'log_dir': '../log', 'distributed': 1, 'gpu': '2,3', 'master_addr': 'localhost', 'master_port': '1984', 'logging_level': 20, 'data_path': '../data', 'item_indexing': 'sequential', 'tasks': 'sequential,straightforward', 'datasets': 'Movietweetings_lab', 'prompt_file': '../../prompt.txt', 'sequential_order': 'original', 'collaborative_token_size': 200, 'collaborative_cluster': 20, 'collaborative_last_token': 'sequential', 'collaborative_float32': 0, 'max_his': 20, 'his_prefix': 1, 'his_sep': ' , ', 'skip_empty_his': 1, 'valid_prompt': 'seen:0', 'valid_prompt_sample': 1, 'valid_sample_num': '3,3', 'test_prompt': 'unseen:0', 'sample_prompt': 1, 'sample_num': '3,3', 'batch_size': 128, 'eval_batch_size': 1, 'dist_sampler': 0, 'optim': 'AdamW', 'epochs': 5, 'lr': 0.001, 'clip': 1, 'logging_step': 100, 'warmup_prop': 0.05, 'gradient_accumulation_steps': 1, 'weight_decay': 0.01, 'adam_eps': 1e-06, 'dropout': 0.1, 'alpha': 2, 'train': 1, 'backbone': 't5-small', 'metrics': 'hit@5,hit@10,ndcg@5,ndcg@10', 'load': 0, 'random_initialize': 1, 'test_epoch': 0, 'valid_select': 0, 'test_before_train': 1, 'test_filtered': 1, 'test_filtered_batch': 0, 'world_size': 2, 'rank': 0, 'log_name': '1_1_1_1_20_1984_Movietweetings_lab_sequential,straightforward_t5-small_sequential_0.001_5_128_3,3_prompt', 'model_path': '../checkpoint/Movietweetings_sequential.pt'}
2025-03-31 04:25:46,637 - root - INFO - Generating data for Movietweetings_lab dataset
2025-03-31 04:25:46,637 - root - INFO - Get prompt template from ../../prompt.txt
2025-03-31 04:25:46,640 - root - INFO - Considering {dataset} user_{user_id} has interacted with {dataset} items {history} . What is the next recommendation for the user ?
2025-03-31 04:25:46,640 - root - INFO - Required info: ['history', 'user_id', 'target', 'dataset']
2025-03-31 04:25:46,643 - root - INFO - Reindex data with sequential indexing method
2025-03-31 04:26:02,885 - root - INFO - loading training data
2025-03-31 04:26:02,890 - root - INFO - Getting prompt information
2025-03-31 04:26:02,938 - root - INFO - Input: Here is the purchase history of Movietweetings_lab user_1 : Movietweetings_lab item item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 . I wonder what is the next recommended item for the user . , Output: Movietweetings_lab item_1035 
2025-03-31 04:26:03,028 - root - INFO - Use t5-small backbone model
2025-03-31 04:26:04,905 - root - INFO - Random initialize number related tokens
2025-03-31 04:26:06,521 - root - INFO - Building Optimizer and Scheduler
2025-03-31 04:26:06,521 - root - INFO - Batch per epoch: 40
2025-03-31 04:26:06,521 - root - INFO - Total steps: 200
2025-03-31 04:26:06,522 - root - INFO - Warmup proportion: 0.05
2025-03-31 04:26:06,522 - root - INFO - Warm up steps: 10
2025-03-31 04:26:06,523 - root - INFO - Building Optimizer AdamW
2025-03-31 04:26:06,627 - root - INFO - Start training
2025-03-31 04:26:06,630 - root - INFO - testing filtered Movietweetings_lab dataset on sequential task
2025-03-31 04:26:15,297 - root - INFO - hit@5: 0.125
2025-03-31 04:26:15,298 - root - INFO - hit@10: 0.171875
2025-03-31 04:26:15,298 - root - INFO - ndcg@5: 0.13889376730432856
2025-03-31 04:26:15,298 - root - INFO - ndcg@10: 0.2035266180466379
2025-03-31 04:26:15,298 - root - INFO - testing filtered Movietweetings_lab dataset on straightforward task
2025-03-31 04:26:23,521 - root - INFO - hit@5: 0.03125
2025-03-31 04:26:23,521 - root - INFO - hit@10: 0.203125
2025-03-31 04:26:23,521 - root - INFO - ndcg@5: 0.092139347464981
2025-03-31 04:26:23,522 - root - INFO - ndcg@10: 0.1978127964599649
2025-03-31 04:26:23,522 - root - INFO - Start training for epoch 1
2025-03-31 04:26:23,569 - root - INFO - Input: Here is the purchase history of Movietweetings_lab user_1 : Movietweetings_lab item item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 . I wonder what is the next recommended item for the user . , Output: Movietweetings_lab item_1035 
2025-03-31 04:26:35,939 - root - INFO - The average training loss for epoch 1 is 2.389951467514038
2025-03-31 04:26:35,940 - root - INFO - Start training for epoch 2
2025-03-31 04:26:35,986 - root - INFO - Input: According to what items Movietweetings_lab user_1 has purchased : Movietweetings_lab items item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 , Can you recommend another item to the user ? , Output: Movietweetings_lab item_1035 
2025-03-31 04:26:48,231 - root - INFO - The average training loss for epoch 2 is 0.6849206686019897
2025-03-31 04:26:48,232 - root - INFO - Start training for epoch 3
2025-03-31 04:26:48,277 - root - INFO - Input: Can you recommend the next item for Movietweetings_lab user_1 , given the user 's purchase of Movietweetings_lab items item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 ? , Output: Movietweetings_lab item_1035 
2025-03-31 04:27:00,577 - root - INFO - The average training loss for epoch 3 is 0.598284125328064
2025-03-31 04:27:00,577 - root - INFO - Start training for epoch 4
2025-03-31 04:27:00,623 - root - INFO - Input: What would Movietweetings_lab user_1 be likely to purchase next after buying Movietweetings_lab items item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 ? , Output: Movietweetings_lab item_1035 
2025-03-31 04:27:12,972 - root - INFO - The average training loss for epoch 4 is 0.556624174118042
2025-03-31 04:27:12,972 - root - INFO - Start training for epoch 5
2025-03-31 04:27:13,018 - root - INFO - Input: I find the purchase list of Movietweetings_lab user_1 : Movietweetings_lab items item_1015 , item_1016 , item_1017 , item_1018 , item_1019 , item_1020 , item_1021 , item_1022 , item_1023 , item_1024 , item_1025 , item_1026 , item_1027 , item_1028 , item_1029 , item_1030 , item_1031 , item_1032 , item_1033 , item_1034 , I wonder what other itmes does the user need . Can you help me decide ? , Output: Movietweetings_lab item_1035 
2025-03-31 04:27:25,352 - root - INFO - The average training loss for epoch 5 is 0.5361054539680481
2025-03-31 04:27:25,870 - root - INFO - Save the current model to ../checkpoint/Movietweetings_sequential.pt
2025-03-31 04:27:25,871 - root - INFO - Load model from ../checkpoint/Movietweetings_sequential.pt
2025-03-31 04:27:26,005 - root - INFO - testing filtered Movietweetings_lab dataset on sequential task
2025-03-31 04:27:34,342 - root - INFO - hit@5: 0.125
2025-03-31 04:27:34,342 - root - INFO - hit@10: 0.15625
2025-03-31 04:27:34,342 - root - INFO - ndcg@5: 0.17630892257802072
2025-03-31 04:27:34,342 - root - INFO - ndcg@10: 0.2355629917927999
2025-03-31 04:27:34,342 - root - INFO - testing filtered Movietweetings_lab dataset on straightforward task
2025-03-31 04:27:42,629 - root - INFO - hit@5: 0.109375
2025-03-31 04:27:42,629 - root - INFO - hit@10: 0.125
2025-03-31 04:27:42,629 - root - INFO - ndcg@5: 0.17026434746498098
2025-03-31 04:27:42,629 - root - INFO - ndcg@10: 0.22531956264859412
